{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean, iqr, skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Collect data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "adult dataset found!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "path = pathlib.Path('../data/adult.csv')\n",
    "if path.exists():\n",
    "    print('adult dataset found!')\n",
    "else:\n",
    "    sys.stdout.write('Downloading the adult dataset from the Internet...')\n",
    "    ADULTURL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "    urllib.request.urlretrieve(ADULTURL, path.absolute())\n",
    "    sys.stdout.write('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Understand the data in context\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      " 10th\n 7th-8th\n Prof-school\n 9th\n 5th-6th\n HS-grad\n Some-college\n Assoc-acdm\n Bachelors\n 1st-4th\n 12th\n Doctorate\n Assoc-voc\n 11th\n Preschool\n Masters\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load the adult dataset into a Pandas dataframe\n",
    "adult_columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', '>50K']\n",
    "adult = pd.read_csv(path.absolute(),names=adult_columns)\n",
    "for i in set(adult['education']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Understand the data\n",
    "### 3.1 Describe the meansing and type for each attribute\n",
    " - **age**: numeric, continuous. \n",
    " - **workclass**: categorical, discrete.\n",
    " - **fnlwgt**: numeric, continuous\n",
    " - **education**: ordinal, discrete\n",
    " - **education-num**: numeric, continuous\n",
    " - **marital-status**: categorical, discrete\n",
    " - **occupation**: categorical, discrete\n",
    " - **relationship**: categorical, discrete\n",
    " - **race**: categorical, discrete\n",
    " - **sex**: categorical, binary\n",
    " - **capital-gain**: numeric, continuous\n",
    " - **capital-loss**: numeric, continuous\n",
    " - **hours-per-week**: numeric, continuous\n",
    " - **native-country**: categorical, discrete\n",
    " - **>50k**: categorical, binary\n",
    "\n",
    "*3.1 subsection: explanation for non-self-explanatory attributes*\n",
    " - **fnlwgt**: represents final weight. according to [2], it's the number of units that this record could represent in the \n",
    " target population. In [1], the author explained that the final weight is controlled by three factors: a single cell estimatation\n",
    " of the population 16+ for each state; controls for Hispanic Origin by age and sex; controls by race, age and sex.\n",
    " - **education_num**: represents the number of years of education in total.[2]\n",
    " - **relationship**: represents the individual's role in it's family.[2]\n",
    " - **capital_gain** and **capital_loss**: represents the income and loss from non-salary ways, e.g. investment.[2]\n",
    " - **education**: due to lack of domain knowledge in U.S. education system, we decided to refer to [3].\n",
    " In which they order the education level in the following manner:  \n",
    " Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate.  \n",
    " [3] further merges  \"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\", \"9th\", \"10th\", \"11th\" and \"12th\" groups to dropout group,\n",
    " \"Assoc-acdm\" and \"Assoc-voc\" groups to \"Associates\" group,“HS-grad” and “Some-college” groups to “HS-Graduate” group.  \n",
    " For us, we would adopt this strategy, merging Prof-school into HS-Graduate group, and instead of arranging the education\n",
    " level like shown above, we have the following order:  \n",
    " dropout < hs-graduate < associates < bachelor < master < doctorate.\n",
    " \n",
    "### 3.2 Verify data quality\n",
    "#### 3.2.1 duplication"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "There are 24 duplicated data entries found.(One copy of the data entry will be kept in the dataset)\nAfter drop duplicate, there are 32537 data entries remains.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Check duplication and drop duplication via pandas built in function\n",
    "check_duplication = adult.duplicated()\n",
    "duplicated = adult[check_duplication]\n",
    "print(\"There are \"+str(len(duplicated.index))+\" duplicated data entries found.(One copy of the data entry will be kept in the dataset)\")\n",
    "adult = adult.drop_duplicates()\n",
    "print(\"After drop duplicate, there are \"+str(len(adult.index))+ \" data entries remains.\")\n",
    "adult = adult.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 missing values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# drop the indexes for which column has value '?'\n",
    "unknown_row =[]\n",
    "\n",
    "for i in range(len(adult.index)):\n",
    "    if ('?' in adult.iloc[i]['workclass']) or ('?' in adult.iloc[i]['occupation']) or ('?' in adult.iloc[i]['native-country']):\n",
    "        unknown_row.append(i)\n",
    "adult = adult.drop(index = unknown_row)\n",
    "adult = adult.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(set(adult['education']))\n",
    "# print(adult.loc[adult['education']==' Preschool'])\n",
    "# print(set(adult['education']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 finding outliers\n",
    "\n",
    "To find outlier, we only focus on numeric values\n",
    "As we can see in the following, the calculated lower bound and upper bound for both capital_gain and capital loss is both\n",
    "0. In 3.3 section we will see that the median for these two value are 0 either. Which means in this dataset most of the people\n",
    "doesn't do investment and thus investment does not incur gain or loss to their income. So for this two attribute we just\n",
    "don't do anything to the outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "By calculating interquantile range, we can get the expected lower/upper bound for each numeric value\nAs explained before we drop the catipal-gain and capital-loss condition, and thus we have\nlower bound as:\nage                  -0.5\nfnlwgt           -62338.0\neducation-num         3.0\nhours-per-week       32.5\ndtype: float64\nand upper bound as:\nage                   75.5\nfnlwgt            417570.0\neducation-num         19.0\nhours-per-week        52.5\ndtype: float64\nAfter reviewing this calculated lower and upper bound, we decided to change some of the value. Since the result\nvalue would be an outlier according to the interquantile range, but still a reasonable value in reality\nThe lower bound of hours-per-week is set to 20, which is the expected value for a part-time job\nThe upper bound of age is set to 85, which is longer than the life expectancy in U.S., and around the value of \nlife expectancy in Canada\nThe upper bound of hours-per-week is set to 72, which is calculated according to the 'famous' 9-9-6 working load\nin China.\nThe upper bound of education-num is set to 26, which is a little bit longer than the expected year of education of\na Ph.D., which is 6 years for elementary, 6 years for middle and high school, 4 year undergraduate, 2 year master\nand 5 year Ph.D. studentship, add up to 23 years.\nAfter applying such filter, we found 2774 outliers in the dataset, which is a pretty large portion of the dataset\nConsider the number of the outliers is quite big, we will just keep them inside the dataset and have a closer\nlook in section 4 Exceptional Work\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# we calculate interquantile range add use it as our guide line as detecting outlier\n",
    "\n",
    "adult_numrics = adult.select_dtypes(include=['int64'])\n",
    "Q1 = adult_numrics.quantile(0.25)\n",
    "Q3 = adult_numrics.quantile(0.75)\n",
    "iqr = Q3-Q1\n",
    "# print(iqr)\n",
    "# print(adult_numrics['capital-gain'])\n",
    "lower_bound = Q1 - 1.5 * iqr\n",
    "upper_bound = Q3 + 1.5 * iqr\n",
    "print(\"By calculating interquantile range, we can get the expected lower/upper bound for each numeric value\")\n",
    "adult_numrics = adult_numrics.drop(['capital-gain','capital-loss'],axis='columns')\n",
    "lower_bound.drop(['capital-gain','capital-loss'],inplace=True)\n",
    "upper_bound.drop(['capital-gain','capital-loss'],inplace=True)\n",
    "print(\"As explained before we drop the catipal-gain and capital-loss condition, and thus we have\")\n",
    "outliers = adult_numrics[((adult_numrics<lower_bound) | (adult_numrics>upper_bound)).any(axis=1)]\n",
    "print(\"lower bound as:\")\n",
    "print(lower_bound)\n",
    "print(\"and upper bound as:\")\n",
    "print(upper_bound)\n",
    "print(\"After reviewing this calculated lower and upper bound, we decided to change some of the value. Since the result\")\n",
    "print(\"value would be an outlier according to the interquantile range, but still a reasonable value in reality\")\n",
    "print(\"The lower bound of hours-per-week is set to 20, which is the expected value for a part-time job\")\n",
    "print(\"The upper bound of age is set to 85, which is longer than the life expectancy in U.S., and around the value of \")\n",
    "print(\"life expectancy in Canada\")\n",
    "print(\"The upper bound of hours-per-week is set to 72, which is calculated according to the \\'famous\\' 9-9-6 working load\")\n",
    "print(\"in China.\")\n",
    "print(\"The upper bound of education-num is set to 26, which is a little bit longer than the expected year of education of\")\n",
    "print(\"a Ph.D., which is 6 years for elementary, 6 years for middle and high school, 4 year undergraduate, 2 year master\")\n",
    "print(\"and 5 year Ph.D. studentship, add up to 23 years.\")\n",
    "\n",
    "lower_bound['hours-per-week'] = 20\n",
    "upper_bound['age']=85\n",
    "upper_bound['hours-per-week']=72\n",
    "upper_bound['education-num'] = 26\n",
    "outliers = adult_numrics[((adult_numrics<lower_bound) | (adult_numrics>upper_bound)).any(axis=1)]\n",
    "print(\"After applying such filter, we found %d outliers in the dataset, which is a pretty large portion of the dataset\"%len(outliers.index))\n",
    "adult_inliers = adult.drop(outliers.index)\n",
    "print(\"Consider the number of the outliers is quite big, we will just keep them inside the dataset and have a closer\")\n",
    "print(\"look in section 4 Exceptional Work\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       age  fnlwgt  education  education-num  capital-gain  capital-loss  \\\n13817   43   19914          2             10             0             0   \n7562    18  274057          1              7             0             0   \n24384   35  160192          2             10             0             0   \n5390    37  323155          1              2             0             0   \n17020   18  238867          1              7             0          1602   \n\n       hours-per-week  >50K  workclass_ Federal-gov  workclass_ Local-gov  \\\n13817              15     0                       1                     0   \n7562                8     0                       0                     0   \n24384              40     0                       0                     0   \n5390               85     0                       0                     0   \n17020              40     0                       0                     0   \n\n       ...  native-country_ Portugal  native-country_ Puerto-Rico  \\\n13817  ...                         0                            0   \n7562   ...                         0                            0   \n24384  ...                         0                            0   \n5390   ...                         0                            0   \n17020  ...                         0                            0   \n\n       native-country_ Scotland  native-country_ South  \\\n13817                         0                      0   \n7562                          0                      0   \n24384                         0                      0   \n5390                          0                      0   \n17020                         0                      0   \n\n       native-country_ Taiwan  native-country_ Thailand  \\\n13817                       0                         0   \n7562                        0                         0   \n24384                       0                         0   \n5390                        0                         0   \n17020                       0                         0   \n\n       native-country_ Trinadad&Tobago  native-country_ United-States  \\\n13817                                0                              1   \n7562                                 0                              1   \n24384                                0                              1   \n5390                                 0                              0   \n17020                                0                              1   \n\n       native-country_ Vietnam  native-country_ Yugoslavia  \n13817                        0                           0  \n7562                         0                           0  \n24384                        0                           0  \n5390                         0                           0  \n17020                        0                           0  \n\n[5 rows x 90 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>&gt;50K</th>\n      <th>workclass_ Federal-gov</th>\n      <th>workclass_ Local-gov</th>\n      <th>...</th>\n      <th>native-country_ Portugal</th>\n      <th>native-country_ Puerto-Rico</th>\n      <th>native-country_ Scotland</th>\n      <th>native-country_ South</th>\n      <th>native-country_ Taiwan</th>\n      <th>native-country_ Thailand</th>\n      <th>native-country_ Trinadad&amp;Tobago</th>\n      <th>native-country_ United-States</th>\n      <th>native-country_ Vietnam</th>\n      <th>native-country_ Yugoslavia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13817</th>\n      <td>43</td>\n      <td>19914</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7562</th>\n      <td>18</td>\n      <td>274057</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24384</th>\n      <td>35</td>\n      <td>160192</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>37</td>\n      <td>323155</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17020</th>\n      <td>18</td>\n      <td>238867</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1602</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 90 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "\"\"\"\n",
    "Numericalize the categorical columns\n",
    "\"\"\"\n",
    "# mapping dictioniary for education row, we take education as a ordinal attribute, as was explained earlier\n",
    "education_mapping_dict = {' Preschool':1, ' 1st-4th':1, ' 5th-6th':1, ' 7th-8th':1, ' 9th':1, ' 10th':1, ' 11th':1, ' 12th':1,\n",
    "                          ' HS-grad':2, ' Prof-school':2, ' Some-college':2,\n",
    "                          ' Assoc-voc':3, ' Assoc-acdm':3,\n",
    "                          ' Bachelors':4,\n",
    "                          ' Masters':5,\n",
    "                          ' Doctorate':6}\n",
    "categorical_list=['workclass','marital-status','occupation','relationship','race','sex','native-country']\n",
    "def categorical_is_converted(input_dtype):\n",
    "    \"\"\"\n",
    "    check if the target categorical value is converted to some integer value\n",
    "    :param input_dtype: the datatype of the input column\n",
    "    :return: True if the dtype is some kind of integer, False otherwise\n",
    "    \"\"\"\n",
    "    return input_dtype in [np.int, np.int64, np.int32, np.long]\n",
    "def one_hot_batch(df, attribute_list,prefix_list=None):\n",
    "    \"\"\"\n",
    "    :param attribute_list: list of attributes that waiting to be one hotted \n",
    "    :param prefix_list: list of prefix for the attribute after one-hot representation, if not set, just use the attribute name\n",
    "    :return: False if unexpected input found, otherwise return the result dataframe\n",
    "    \"\"\"\n",
    "    if prefix_list is None:\n",
    "        prefix_list = attribute_list\n",
    "    if not len(attribute_list) == len(prefix_list):\n",
    "        return False\n",
    "    for i in range(len(attribute_list)):\n",
    "        if not categorical_is_converted(df[attribute_list[i]].dtype):\n",
    "            dummies = pd.get_dummies(df[attribute_list[i]], prefix=prefix_list[i])\n",
    "            df = df.drop(columns=[attribute_list[i]])\n",
    "            df = pd.concat([df,dummies], axis=1)\n",
    "    return df\n",
    "# map education to integers\n",
    "if not categorical_is_converted(adult['education'].dtype):\n",
    "    adult = adult.replace({'education': education_mapping_dict})\n",
    "# convert all non-ordinal categorical attribute using one-hot representation\n",
    "adult = one_hot_batch(adult, categorical_list)\n",
    "# map the prediction target: the ultimate income rank into integer. Since it's binary, we don't use one hot representation\n",
    "if not categorical_is_converted(adult['>50K'].dtype):\n",
    "    for i in range(len(adult.index)):\n",
    "        if '>50K' in adult.iloc[i]['>50K']:\n",
    "            adult.iloc[i, adult.columns.get_loc('>50K')] = 1\n",
    "        else:\n",
    "            adult.iloc[i,adult.columns.get_loc('>50K')] = 0\n",
    "adult.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Statistics about Numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# select all columns with numeric values\n",
    "adult_numeric = adult.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult_numeric.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cnames = ['mean', 'median', 'mode', 'trimmed mean (p=20%)', 'min', 'max', 'range', 'std']\n",
    "adult_numeric.agg(lambda x: pd.Series([np.mean(x), np.median(x),x.mode()[0], trim_mean(x, 0.2),x.min(),x.max(),x.max()-x.min(),x.std()], index=cnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Statistics about Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# select all columns with categorical values\n",
    "adult_categorical = adult.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult_categorical.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cnames = adult_categorical.columns.tolist()\n",
    "cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult_categorical['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult_categorical['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult_categorical['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult['relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult.groupby('workclass').agg(['mean', lambda x: trim_mean(x, 0.2), 'median', 'std']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "adult.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reference\n",
    "    [1] Kaggle adult census income dataset. Date accessed: Sept. 2019. url: https://www.kaggle.com/uciml/adult-census-income\n",
    "    [2] Haojun Zhu, Predicting Earning Potential using the Adult Dataset. Dec. 2016. url: https://rstudio-pubs-static.s3.amazonaws.com/235617_51e06fa6c43b47d1b6daca2523b2f9e4.html\n",
    "    [3] Bui Dinh Chien, Jean-Daniel Zucker, Complex Data Mining Project. Date accessed: Sept. 2019. url: https://sites.google.com/site/complexdataminingproject/."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}